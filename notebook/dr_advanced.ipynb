{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7aaf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from telegram import Update\n",
    "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d11873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths ---\n",
    "train_image_path = \"/home/sifat/AI/data/train_image\"\n",
    "train_label_path = \"/home/sifat/AI/data/train_label\"\n",
    "test_image_path = \"/home/sifat/AI/data/test_image\"\n",
    "test_label_path = \"/home/sifat/AI/data/test_label\"\n",
    "BOT_TOKEN = \"6846587660:AAH9R-W7D3qn98mBfFROiD9vGaixIrwEAno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e236877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load MNIST functions ---\n",
    "def load_images(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    magic, num, row, col = np.frombuffer(data[:16], dtype=\">i4\")\n",
    "    if magic != 2051:\n",
    "        raise ValueError(\"Invalid image file\")\n",
    "    imgs = np.frombuffer(data[16:], dtype=np.uint8).reshape(num, row*col)\n",
    "    return imgs.astype(np.float32)/255.0\n",
    "\n",
    "def load_labels(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    magic, num = np.frombuffer(data[:8], dtype=\">i4\")\n",
    "    if magic != 2049:\n",
    "        raise ValueError(\"Invalid label file\")\n",
    "    labels = np.frombuffer(data[8:], dtype=np.uint8)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a10583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, num_classes=10):\n",
    "    out = np.zeros((y.shape[0], num_classes))\n",
    "    out[np.arange(y.shape[0]), y] = 1\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80680322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data...\n"
     ]
    }
   ],
   "source": [
    "# --- Load raw MNIST data directly ---\n",
    "print(\"Loading MNIST data...\")\n",
    "X_train = load_images(train_image_path)\n",
    "Y_train = one_hot(load_labels(train_label_path))\n",
    "X_test = load_images(test_image_path)\n",
    "Y_test = one_hot(load_labels(test_label_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d073ba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new weights...\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize or load CNN weights ---\n",
    "if os.path.exists(\"conv1_W.npy\") and os.path.exists(\"conv1_b.npy\") \\\n",
    "   and os.path.exists(\"fc_W.npy\") and os.path.exists(\"fc_b.npy\"):\n",
    "    print(\"Loading existing weights...\")\n",
    "    conv1_W = np.load(\"conv1_W.npy\")\n",
    "    conv1_b = np.load(\"conv1_b.npy\")\n",
    "    fc_W = np.load(\"fc_W.npy\")\n",
    "    fc_b = np.load(\"fc_b.npy\")\n",
    "else:\n",
    "    print(\"Initializing new weights...\")\n",
    "    conv1_W = np.random.randn(8,3,3)*0.1\n",
    "    conv1_b = np.zeros(8)\n",
    "    fc_W = np.random.randn(8*13*13,10)*0.1\n",
    "    fc_b = np.zeros(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CNN layers ---\n",
    "def conv2d(X, W, b, stride=1):\n",
    "    n_filters, f_h, f_w = W.shape\n",
    "    H, W_in = X.shape\n",
    "    out_h = H - f_h + 1\n",
    "    out_w = W_in - f_w + 1\n",
    "    out = np.zeros((n_filters, out_h, out_w))\n",
    "    for k in range(n_filters):\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                out[k,i,j] = np.sum(X[i:i+f_h,j:j+f_w]*W[k]) + b[k]\n",
    "    return out\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0, X)\n",
    "\n",
    "def relu_grad(X):\n",
    "    return (X > 0).astype(np.float32)\n",
    "\n",
    "def maxpool2d(X, size=2, stride=2):\n",
    "    n_filters, H, W_in = X.shape\n",
    "    out_h = (H - size)//stride +1\n",
    "    out_w = (W_in - size)//stride +1\n",
    "    out = np.zeros((n_filters, out_h, out_w))\n",
    "    for k in range(n_filters):\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                out[k,i,j] = np.max(X[k,i*stride:i*stride+size,j*stride:j*stride+size])\n",
    "    return out\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x)\n",
    "    e = np.exp(x)\n",
    "    return e/np.sum(e)\n",
    "\n",
    "# --- Forward pass ---\n",
    "def forward(img):\n",
    "    conv_out = conv2d(img, conv1_W, conv1_b)\n",
    "    conv_out_relu = relu(conv_out)\n",
    "    pooled = maxpool2d(conv_out_relu)\n",
    "    flat = pooled.flatten().reshape(1,-1)\n",
    "    logits = flat @ fc_W + fc_b\n",
    "    probs = softmax(logits)\n",
    "    cache = (conv_out, conv_out_relu, pooled, flat)\n",
    "    return probs, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training hyperparameters ---\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "lr = 0.01\n",
    "\n",
    "for e in range(epochs):\n",
    "    idx = np.random.permutation(X_train.shape[0])\n",
    "    X_train_shuffled = X_train[idx]\n",
    "    Y_train_shuffled = Y_train[idx]\n",
    "    batch_loss = 0\n",
    "\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = X_train_shuffled[i:i+batch_size]\n",
    "        Y_batch = Y_train_shuffled[i:i+batch_size]\n",
    "\n",
    "        d_fc_W = np.zeros_like(fc_W)\n",
    "        d_fc_b = np.zeros_like(fc_b)\n",
    "        d_conv_W = np.zeros_like(conv1_W)\n",
    "        d_conv_b = np.zeros_like(conv1_b)\n",
    "\n",
    "        for j in range(X_batch.shape[0]):\n",
    "            img = X_batch[j].reshape(28,28)  # reshape to 2D\n",
    "            y_true = Y_batch[j].reshape(1,-1)\n",
    "            probs, cache = forward(img)\n",
    "            conv_out, conv_out_relu, pooled, flat = cache\n",
    "            batch_loss += -np.sum(y_true*np.log(probs+1e-15))\n",
    "\n",
    "            dlogits = probs - y_true\n",
    "            d_fc_W += flat.T @ dlogits\n",
    "            d_fc_b += dlogits.flatten()\n",
    "\n",
    "            d_flat = dlogits @ fc_W.T\n",
    "            d_pooled = d_flat.reshape(pooled.shape)\n",
    "\n",
    "            d_conv_relu = np.zeros_like(conv_out_relu)\n",
    "            n_filters, out_h, out_w = pooled.shape\n",
    "            for k in range(n_filters):\n",
    "                for i_pool in range(out_h):\n",
    "                    for j_pool in range(out_w):\n",
    "                        patch = conv_out_relu[k,i_pool*2:i_pool*2+2,j_pool*2:j_pool*2+2]\n",
    "                        max_idx = np.unravel_index(np.argmax(patch), patch.shape)\n",
    "                        d_conv_relu[k,i_pool*2 + max_idx[0], j_pool*2 + max_idx[1]] = d_pooled[k,i_pool,j_pool]\n",
    "\n",
    "            d_conv = d_conv_relu * relu_grad(conv_out)\n",
    "\n",
    "            for k in range(conv1_W.shape[0]):\n",
    "                for i_f in range(conv1_W.shape[1]):\n",
    "                    for j_f in range(conv1_W.shape[2]):\n",
    "                        d_conv_W[k,i_f,j_f] += np.sum(d_conv[k] * img[i_f:i_f + d_conv.shape[1], j_f:j_f + d_conv.shape[2]])\n",
    "                d_conv_b[k] += np.sum(d_conv[k])\n",
    "\n",
    "        conv1_W -= lr * d_conv_W / X_batch.shape[0]\n",
    "        conv1_b -= lr * d_conv_b / X_batch.shape[0]\n",
    "        fc_W -= lr * d_fc_W / X_batch.shape[0]\n",
    "        fc_b -= lr * d_fc_b / X_batch.shape[0]\n",
    "\n",
    "    batch_loss /= X_train.shape[0]\n",
    "\n",
    "    correct = 0\n",
    "    for j in range(X_train.shape[0]):\n",
    "        img = X_train[j].reshape(28,28)\n",
    "        probs, _ = forward(img)\n",
    "        pred = np.argmax(probs)\n",
    "        label = np.argmax(Y_train[j])\n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "    acc = correct / X_train.shape[0]\n",
    "    print(f\"Epoch {e+1}/{epochs}, Loss: {batch_loss:.4f}, Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# --- Save weights ---\n",
    "np.save(\"conv1_W.npy\", conv1_W)\n",
    "np.save(\"conv1_b.npy\", conv1_b)\n",
    "np.save(\"fc_W.npy\", fc_W)\n",
    "np.save(\"fc_b.npy\", fc_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab56f201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test accuracy ---\n",
    "correct = 0\n",
    "for j in range(X_test.shape[0]):\n",
    "    img = X_test[j].reshape(28,28)\n",
    "    probs, _ = forward(img)\n",
    "    pred = np.argmax(probs)\n",
    "    label = np.argmax(Y_test[j])\n",
    "    if pred == label:\n",
    "        correct += 1\n",
    "test_acc = correct / X_test.shape[0]\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
